{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week3_Quiz_Lesson5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunnieLee/data_science_tutorials/blob/master/week3_Quiz_Lesson5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ifaOKTzxPC1z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. [6-3] Mann-Whitney U-Test"
      ]
    },
    {
      "metadata": {
        "id": "vAfoHJlhCyyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import pandas\n",
        "\n",
        "def mann_whitney_plus_means(turnstile_weather):\n",
        "    '''\n",
        "    This function will consume the turnstile_weather dataframe containing\n",
        "    our final turnstile weather data. \n",
        "    \n",
        "    You will want to take the means and run the Mann Whitney U-test on the \n",
        "    ENTRIESn_hourly column in the turnstile_weather dataframe.\n",
        "    \n",
        "    This function should return:\n",
        "        1) the mean of entries with rain\n",
        "        2) the mean of entries without rain\n",
        "        3) the Mann-Whitney U-statistic and p-value comparing the number of entries\n",
        "           with rain and the number of entries without rain\n",
        "    '''\n",
        "    \n",
        "    with_rain = turnstile_weather[turnstile_weather['rain']==0]\n",
        "    without_rain = turnstile_weather[turnstile_weather['rain']==1]\n",
        "    \n",
        "    with_rain_mean = with_rain.loc[:,'ENTRIESn_hourly'].mean()\n",
        "    without_rain_mean = without_rain.loc[:,'ENTRIESn_hourly'].mean()\n",
        "    \n",
        "    U, p = scipy.stats.mannwhitneyu(with_rain.loc[:,'ENTRIESn_hourly'], without_rain.loc[:,'ENTRIESn_hourly'])\n",
        "\n",
        "    return with_rain_mean, without_rain_mean, U, p # leave this line for the grader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sUZbkaoMPJiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. [6-5] Linear Regression"
      ]
    },
    {
      "metadata": {
        "id": "85P6WnRHPPJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "from ggplot import *\n",
        "\n",
        "\"\"\"\n",
        "In this question, you need to:\n",
        "1) implement the compute_cost() and gradient_descent() procedures\n",
        "2) Select features (in the predictions procedure) and make predictions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def normalize_features(df):\n",
        "    \"\"\"\n",
        "    Normalize the features in the data set.\n",
        "    \"\"\"\n",
        "    mu = df.mean()\n",
        "    sigma = df.std()\n",
        "    \n",
        "    if (sigma == 0).any():\n",
        "        raise Exception(\"One or more features had the same value for all samples, and thus could \" + \\\n",
        "                         \"not be normalized. Please do not include features with only a single value \" + \\\n",
        "                         \"in your model.\")\n",
        "    df_normalized = (df - df.mean()) / df.std()\n",
        "\n",
        "    return df_normalized, mu, sigma\n",
        "\n",
        "# 1.\n",
        "def compute_cost(features, values, theta):\n",
        "    m = len(values)\n",
        "    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n",
        "    cost = sum_of_square_errors / (2*m)\n",
        "    return cost\n",
        "\n",
        "\n",
        "# 2.\n",
        "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
        "    m = len(values)\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        predicted_values = np.dot(features, theta)\n",
        "        theta = theta - alpha/m*np.dot((predicted_values-values), features)\n",
        "        cost = compute_cost(features, values, theta)\n",
        "        cost_history.append(cost)\n",
        "    return theta, pandas.Series(cost_history)\n",
        "\n",
        "\n",
        "def predictions(dataframe):\n",
        "    '''\n",
        "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
        "    Using the information stored in the dataframe, let's predict the ridership of\n",
        "    the NYC subway using linear regression with gradient descent.\n",
        "    \n",
        "    You can download the complete turnstile weather dataframe here:\n",
        "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
        "    \n",
        "    Your prediction should have a R^2 value of 0.40 or better.\n",
        "    You need to experiment using various input features contained in the dataframe. \n",
        "    We recommend that you don't use the EXITSn_hourly feature as an input to the \n",
        "    linear model because we cannot use it as a predictor: we cannot use exits \n",
        "    counts as a way to predict entry counts. \n",
        "    \n",
        "    Note: Due to the memory and CPU limitation of our Amazon EC2 instance, we will\n",
        "    give you a random subet (~15%) of the data contained in \n",
        "    turnstile_data_master_with_weather.csv. You are encouraged to experiment with \n",
        "    this computer on your own computer, locally. \n",
        "    \n",
        "    \n",
        "    If you'd like to view a plot of your cost history, uncomment the call to \n",
        "    plot_cost_history below. The slowdown from plotting is significant, so if you \n",
        "    are timing out, the first thing to do is to comment out the plot command again.\n",
        "    \n",
        "    If you receive a \"server has encountered an error\" message, that means you are \n",
        "    hitting the 30-second limit that's placed on running your program. Try using a \n",
        "    smaller number for num_iterations if that's the case.\n",
        "    \n",
        "    If you are using your own algorithm/models, see if you can optimize your code so \n",
        "    that it runs faster.\n",
        "    '''\n",
        "    # Select Features (try different features!)\n",
        "    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi']]\n",
        "    \n",
        "    # Add UNIT to features using dummy variables\n",
        "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
        "    features = features.join(dummy_units)\n",
        "    \n",
        "    # Values\n",
        "    values = dataframe['ENTRIESn_hourly']\n",
        "    m = len(values)\n",
        "\n",
        "    features, mu, sigma = normalize_features(features)\n",
        "    features['ones'] = np.ones(m) # Add a column of 1s (y intercept)\n",
        "    \n",
        "    # Convert features and values to numpy arrays\n",
        "    features_array = np.array(features)\n",
        "    values_array = np.array(values)\n",
        "\n",
        "    # Set values for alpha, number of iterations.\n",
        "    alpha = 0.1 # please feel free to change this value\n",
        "    num_iterations = 75 # please feel free to change this value\n",
        "\n",
        "    # Initialize theta, perform gradient descent\n",
        "    theta_gradient_descent = np.zeros(len(features.columns))\n",
        "    theta_gradient_descent, cost_history = gradient_descent(features_array, \n",
        "                                                            values_array, \n",
        "                                                            theta_gradient_descent, \n",
        "                                                            alpha, \n",
        "                                                            num_iterations)\n",
        "    \n",
        "    plot = None\n",
        "    # -------------------------------------------------\n",
        "    # Uncomment the next line to see your cost history\n",
        "    # -------------------------------------------------\n",
        "    # plot = plot_cost_history(alpha, cost_history)\n",
        "    # \n",
        "    # Please note, there is a possibility that plotting\n",
        "    # this in addition to your calculation will exceed \n",
        "    # the 30 second limit on the compute servers.\n",
        "    \n",
        "    predictions = np.dot(features_array, theta_gradient_descent)\n",
        "    return predictions, plot\n",
        "\n",
        "\n",
        "def plot_cost_history(alpha, cost_history):\n",
        "   \"\"\"This function is for viewing the plot of your cost history.\n",
        "   You can run it by uncommenting this\n",
        "\n",
        "       plot_cost_history(alpha, cost_history) \n",
        "\n",
        "   call in predictions.\n",
        "   \n",
        "   If you want to run this locally, you should print the return value\n",
        "   from this function.\n",
        "   \"\"\"\n",
        "   cost_df = pandas.DataFrame({\n",
        "      'Cost_History': cost_history,\n",
        "      'Iteration': range(len(cost_history))\n",
        "   })\n",
        "   return ggplot(cost_df, aes('Iteration', 'Cost_History')) + \\\n",
        "      geom_point() + ggtitle('Cost History for alpha = %.3f' % alpha )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2bktl4mDPP2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. [6-7] Compute R^2"
      ]
    },
    {
      "metadata": {
        "id": "1uiwSYhpPR0C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "def compute_r_squared(data, predictions):\n",
        "    r_squared = 1 - np.sum((data-predictions)**2)/np.sum((data-np.mean(data))**2)\n",
        "    return r_squared"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}